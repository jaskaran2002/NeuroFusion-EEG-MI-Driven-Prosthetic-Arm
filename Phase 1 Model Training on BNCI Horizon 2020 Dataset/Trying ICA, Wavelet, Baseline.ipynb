{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9782417,"sourceType":"datasetVersion","datasetId":5993218}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install mne gdown","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport mne\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load dataset\nraws = []\nfor i in range(1,11):\n    raws.append(mne.io.read_raw_gdf(f'/kaggle/input/s02-mi/motorimagination_subject2_run{i}.gdf', preload=True))\n#     raws.append(mne.io.read_raw_gdf('/kaggle/working/S05_MI/motorimagination_subject5_run'+str(i)+'.gdf', preload=True))\n# raws = [mne.io.read_raw_gdf('/kaggle/working/S0'+str(j)+'_MI/motorimagination_subject'+str(j)+'_run'+str(i)+'.gdf', preload=True)for j in range(2,6) for i in range(1,10)]\nraw_data = mne.concatenate_raws(raws)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Channel names:', raw_data.info['ch_names'])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"raw data information\", raw_data.info)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"events_A, event_id_A = mne.events_from_annotations(raw_data)\nprint(events_A)\nprint(event_id_A)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mne.viz.plot_events(events_A)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"event_id = {'1536': 1, '1537': 2, '1538': 3, '1539': 4, '1540': 5, '1541': 6, '1542': 7}\nevents_A, event_id_A = mne.events_from_annotations(raw_data, event_id=event_id)\nprint(events_A)\nprint(event_id_A)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"event_id_A","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#epochs = mne.Epochs(raw_data, events_A, tmin=-0.2, tmax=0.8, event_repeated='merge',preload=True, event_id={'elbow_flexion':1536, 'elbow_extension': 1537, 'supination': 1538, 'pronation':1539,'hand_close':1540,'hand_open':1541,'rest':1542 })\n#epochs = mne.Epochs(raw_data, events_A, tmin=-0.1, tmax=3.0, event_repeated='merge',preload=True, event_id={'elbow_flexion':1, 'elbow_extension': 2, 'supination': 3, 'pronation':4,'hand_close':5,'hand_open':6,'rest':7 })\n\nraw_data.info['bads'] += ['thumb_near', 'thumb_far', 'thumb_index', 'index_near', 'index_far', 'index_middle', 'middle_near', 'middle_far', 'middle_ring', 'ring_near', 'ring_far', 'ring_little', 'litte_near', 'litte_far', 'thumb_palm', 'wrist_bend', 'roll', 'pitch', 'gesture', 'handPosX', 'handPosY', 'handPosZ', 'elbowPosX', 'elbowPosY', 'elbowPosZ', 'ShoulderAdductio', 'ShoulderFlexionE', 'ShoulderRotation', 'Elbow', 'ProSupination', 'Wrist', 'GripPressure']\n# raw_data.info['bads'] += ['eog-r', 'eog-m', 'eog-l', 'thumb_near', 'thumb_far', 'thumb_index', 'index_near', 'index_far', 'index_middle', 'middle_near', 'middle_far', 'middle_ring', 'ring_near', 'ring_far', 'ring_little', 'litte_near', 'litte_far', 'thumb_palm', 'wrist_bend', 'roll', 'pitch', 'gesture', 'handPosX', 'handPosY', 'handPosZ', 'elbowPosX', 'elbowPosY', 'elbowPosZ', 'ShoulderAdductio', 'ShoulderFlexionE', 'ShoulderRotation', 'Elbow', 'ProSupination', 'Wrist', 'GripPressure']\n\npicks = mne.pick_types(raw_data.info, meg=False, eeg=True, eog=True, stim=False,\n                       exclude='bads')\n\n# event_id={'1':1, '2': 2, '3': 3, '4':4,'5':5,'6':6 }\nevent_id={'1':1, '2': 2, '3': 3, '4':4,'5':5,'6':6,'7':7 }\n#event_id={'6':6,'7':7 }\n\n\n# epochs = mne.Epochs(raw_data, events_A, event_id, tmin=1., tmax=2. ,proj=True, baseline=None,picks=picks,preload=True)\nepochs = mne.Epochs(raw_data, events_A, event_id, tmin=-0.01, tmax=5.0, proj=True, picks=picks, preload=True)\nprint(\"epochs information: \", epochs)\nprint(\"epochs dropped for: \", set(epochs.drop_log))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = epochs.events[:,-1]\nlabels","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs.resample(sfreq=256)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"iir_params = dict(order=4, ftype='butter')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs.filter(l_freq=0.5, h_freq=70.0, method='iir',\n              iir_params=iir_params, verbose=True)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Artifact Rejection/Correction:\n## ICA","metadata":{}},{"cell_type":"code","source":"from mne.preprocessing import ICA\n\nica = ICA(n_components=15, random_state=97, max_iter=800)\nica.fit(epochs)\nica.exclude = [0]\nepochs = ica.apply(epochs)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Baseline Correction:","metadata":{}},{"cell_type":"code","source":"epochs.apply_baseline(baseline=(None, 0))  # Baseline correction with pre-stimulus period","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# visualize the average epochs fig for 7 classes\n# epochs['elbow_flexion'].plot_image(title='elbow_flexion', combine='mean')\n# epochs['elbow_extension'].plot_image(title='elbow_extension', combine='mean')\n# epochs['supination'].plot_image(title='supination', combine='mean')\n# epochs['pronation'].plot_image(title='pronation', combine='mean')\n# epochs['hand_close'].plot_image(title='hand_close', combine='mean')\n# epochs['hand_open'].plot_image(title='hand_open', combine='mean')\n# epochs['rest'].plot_image(title='rest', combine='mean')\nepochs['1'].plot_image(title='elbow_flexion', combine='mean')\nepochs['2'].plot_image(title='elbow_extension', combine='mean')\nepochs['3'].plot_image(title='supination', combine='mean')\nepochs['4'].plot_image(title='pronation', combine='mean')\nepochs['5'].plot_image(title='hand_close', combine='mean')\nepochs['6'].plot_image(title='hand_open', combine='mean')\nepochs['7'].plot_image(title='rest', combine='mean')\n\n# plot the evoked fig\n#evoked_dict = {'elbow_flexion': epochs['elbow_flexion'].average(), 'elbow_extension': epochs['elbow_extension'].average(), 'supination': epochs['supination'].average(), 'pronation': epochs['pronation'].average(),'hand_close': epochs['hand_close'].average(),'hand_open': epochs['hand_open'].average(),'rest': epochs['rest'].average()}\nevoked_dict = {'elbow_flexion': epochs['1'].average(), 'elbow_extension': epochs['2'].average(), 'supination': epochs['3'].average(), 'pronation': epochs['4'].average(),'hand_close': epochs['5'].average(),'hand_open': epochs['6'].average(),'rest': epochs['7'].average()}\n# evoked_dict = {'elbow_flexion': epochs['1'].average(), 'elbow_extension': epochs['2'].average(), 'supination': epochs['3'].average(), 'pronation': epochs['4'].average(),'hand_close': epochs['5'].average(),'hand_open': epochs['6'].average()}\nmne.viz.plot_compare_evokeds(evoked_dict)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evoked = epochs['1'].average()\n# print(evoked)\nevoked.plot(time_unit='s')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = epochs.get_data()*1000","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\nX_out = enc.fit_transform(labels.reshape(-1,1)).toarray()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_out.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(data, X_out, test_size=0.2, random_state=0)\nprint(\"X_train\",X_train.shape)\nprint(\"X_test\",X_test.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"y_test\",y_test.shape)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Temporal Smoothing:","metadata":{}},{"cell_type":"code","source":"from scipy.ndimage import gaussian_filter1d\n\ndef smooth_data(data, sigma=1):\n    \"\"\"\n    Apply Gaussian smoothing to the EEG data.\n    \n    Parameters:\n    - data: ndarray, shape (samples, channels, timepoints)\n    - sigma: float, standard deviation for Gaussian kernel\n    \n    Returns:\n    - smoothed_data: ndarray with smoothed values\n    \"\"\"\n    smoothed_data = np.zeros_like(data)\n    for i in range(data.shape[0]):  # Iterate over each sample\n        for ch in range(data.shape[1]):  # Iterate over each channel\n            smoothed_data[i, ch, :] = gaussian_filter1d(data[i, ch, :], sigma=sigma)\n    \n    return smoothed_data\n\n# Example usage:\nX_train = smooth_data(X_train)\nX_test = smooth_data(X_test)\n\nprint(\"Smoothed data shape:\", X_train.shape)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# XLSTM","metadata":{}},{"cell_type":"code","source":"num_units = 128\nwindow_size = 64\nnum_epochs = 25","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_size = 1283\nsequence_length = 64\nnum_layers = 2\nhidden_size = 64\noutput_size = 7","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install xlstm  torcheval","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xlstm import (\n    xLSTMBlockStack,\n    xLSTMBlockStackConfig,\n    mLSTMBlockConfig,\n    mLSTMLayerConfig,\n    sLSTMBlockConfig,\n    sLSTMLayerConfig,\n    FeedForwardConfig,\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mlstm_config = mLSTMBlockConfig()\n\n# for cpu\n# slstm_config = sLSTMBlockConfig()\n\n# for gpu\nslstm_config = sLSTMBlockConfig(slstm=sLSTMLayerConfig(\n            backend=\"cuda\"\n        ))\n\n\ncfg = xLSTMBlockStackConfig(\n        mlstm_block=mlstm_config,\n        slstm_block=slstm_config,\n        num_blocks=3,\n        embedding_dim=input_size,\n        add_post_blocks_norm=True,\n        \n        _block_map = 1,\n        context_length=sequence_length\n    )","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TestModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size):\n        super(TestModel, self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.output_size = output_size\n#         self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n        self.xlstm = xLSTMBlockStack(cfg)\n        # x -> (batch_size, sequence_length, input_size)\n        self.fc = nn.Linear(input_size,output_size)\n        self.tanh = nn.Tanh()\n    def forward(self, x):\n        out = self.xlstm(x)\n        # x -> (batch_size, sequence_length, hidden_size)\n        out = self.tanh(out)\n        out = out[:,-1,:]\n        out = self.fc(out)\n        return out","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = TestModel(input_size, hidden_size, num_layers, output_size).to(device)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learning_rate=0.0001","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 100","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = torch.tensor(X_train)\ny_train = torch.tensor(y_train)\nX_test = torch.tensor(X_test)\ny_test = torch.tensor(y_test)\n\nX_train = X_train.to(device)\ny_train = y_train.to(device)\nX_test = X_test.to(device)\ny_test = y_test.to(device)\n\n\nX_train = X_train.float()\ny_train = y_train.float()\nX_test = X_test.float()\ny_test = y_test.float()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.utils.data as data\nfrom tqdm.notebook import tqdm\nfrom torcheval.metrics import MulticlassAccuracy\nimport torcheval","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metric = MulticlassAccuracy(num_classes=7)\ntestLoader = data.DataLoader(data.TensorDataset(X_test, y_test), shuffle=True, batch_size=32)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in tqdm(range(num_epochs)):\n    model.train()\n    for X_batch, y_batch in tqdm(loader):\n        y_pred = model(X_batch)\n        loss = criterion(y_pred, y_batch.argmax(1))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    model.eval()\n    totalYPred = []\n    totalY = []\n    with torch.no_grad():\n        for X_batch, y_batch in loader:\n            totalY.append(y_batch)\n            totalYPred.append(model(X_batch))\n    actualY = torch.cat(totalY, 0)\n    predY = torch.cat(totalYPred, 0)\n    metric.update(torch.nn.functional.softmax(predY, dim=-1).argmax(1), actualY.argmax(1))\n    train_acc = metric.compute()\n    print(\"Epoch %d: train Accuracy %.4f,\" % (epoch, train_acc), end=\"\")\n    \n    totalYPred = []\n    totalY = []\n    with torch.no_grad():\n        for X_batch, y_batch in testLoader:\n            totalY.append(y_batch)\n            totalYPred.append(model(X_batch))\n    actualY = torch.cat(totalY, 0)\n    predY = torch.cat(totalYPred, 0)\n    metric.update(torch.nn.functional.softmax(predY, dim=-1).argmax(1), actualY.argmax(1))\n    test_acc = metric.compute()\n    print(\" test Accuracy %.4f\" % (test_acc))\n    del totalYPred\n    del totalY\n    del actualY\n    del predY","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/xlstm21.model')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/entireModel21.model')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}